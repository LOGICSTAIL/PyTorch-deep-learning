{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "8.1. GAN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HQw0kKzh3mt"
      },
      "source": [
        "Modified from:  https://towardsdatascience.com/getting-started-with-gans-using-pytorch-78e7c22a14a5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXZ4l4QHJ2Sf"
      },
      "source": [
        "### I modify the input image from 64x64 to 128x128"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDeNCYYzlMXy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fd5999f-ad2e-4322-809b-f608a6b73fa8"
      },
      "source": [
        "import torch\n",
        "if(torch.cuda.is_available()):\n",
        "  device = torch.device(\"cuda\")\n",
        "  print(device, torch.cuda.get_device_name(0))\n",
        "else:\n",
        "  device= torch.device(\"cpu\")\n",
        "  print(device)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzDSC_nh7VoZ"
      },
      "source": [
        "import torch.nn as nn"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLdSCpeQf8s7"
      },
      "source": [
        "latent_size=64"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYQpEktI0vGG"
      },
      "source": [
        "generator = nn.Sequential(\n",
        "    # in: latent_size x 1 x 1\n",
        "\n",
        "    nn.ConvTranspose2d(latent_size, 512, kernel_size=4, stride=1, padding=0, bias=False),\n",
        "    nn.BatchNorm2d(512),\n",
        "    nn.ReLU(True),\n",
        "    # out: 512 x 4 x 4\n",
        "\n",
        "    nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(256),\n",
        "    nn.ReLU(True),\n",
        "    # out: 256 x 8 x 8\n",
        "\n",
        "    nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(128),\n",
        "    nn.ReLU(True),\n",
        "    # out: 128 x 16 x 16\n",
        "\n",
        "    nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(64),\n",
        "    nn.ReLU(True),\n",
        "    # out: 64 x 32 x 32\n",
        "\n",
        "    nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(32),\n",
        "    nn.ReLU(True),\n",
        "    # out: 32 x 64 x 64\n",
        "\n",
        "    nn.ConvTranspose2d(32, 3, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.Tanh()\n",
        "    # out: 3 x 128 x 128\n",
        ")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhnfT18tlDc3",
        "outputId": "76c01992-a599-4edd-a833-17684f583c3c"
      },
      "source": [
        "generator.to(device)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): ConvTranspose2d(64, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
              "  (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (2): ReLU(inplace=True)\n",
              "  (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "  (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (5): ReLU(inplace=True)\n",
              "  (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "  (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (8): ReLU(inplace=True)\n",
              "  (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "  (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (11): ReLU(inplace=True)\n",
              "  (12): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "  (13): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (14): ReLU(inplace=True)\n",
              "  (15): ConvTranspose2d(32, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "  (16): Tanh()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-PA-xad0zbH"
      },
      "source": [
        "discriminator = nn.Sequential(\n",
        "    # in: 3 x 128 x 128\n",
        "\n",
        "    nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(64),\n",
        "    nn.LeakyReLU(0.2, inplace=True),\n",
        "    # out: 64 x 64 x 64\n",
        "\n",
        "    nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(128),\n",
        "    nn.LeakyReLU(0.2, inplace=True),\n",
        "    # out: 128 x 32 x 32\n",
        "\n",
        "    nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(256),\n",
        "    nn.LeakyReLU(0.2, inplace=True),\n",
        "    # out: 256 x 16 x 16\n",
        "\n",
        "    nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(512),\n",
        "    nn.LeakyReLU(0.2, inplace=True),\n",
        "    # out: 512 x 8 x 8\n",
        "\n",
        "    nn.Conv2d(512, 1024, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "    nn.BatchNorm2d(1024),\n",
        "    nn.LeakyReLU(0.2, inplace=True),\n",
        "    # out: 1024 x 4 x 4\n",
        "\n",
        "    nn.Conv2d(1024, 1, kernel_size=4, stride=1, padding=0, bias=False),\n",
        "    # out: 1 x 1 x 1\n",
        "\n",
        "    nn.Flatten(),\n",
        "    nn.Sigmoid())"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxxP32ZTk9dg",
        "outputId": "f21307eb-f185-41ac-e174-8829c4d8ea5e"
      },
      "source": [
        "discriminator.to(device)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "  (3): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "  (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "  (6): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "  (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (8): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "  (9): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "  (10): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (11): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "  (12): Conv2d(512, 1024, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "  (13): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (14): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "  (15): Conv2d(1024, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
              "  (16): Flatten(start_dim=1, end_dim=-1)\n",
              "  (17): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ms8ZwYl8KTUd"
      },
      "source": [
        "#Connect to Google drive to generate data loader\n",
        "If you train using your own PC with Anaconda\n",
        "1. do not run drive.mount (\"/content/gdrive\", force_remount=True)\n",
        "2. train_dataset = datasets.ImageFolder(root = \"C:/Users/ADMIN/Google 雲端硬碟/Image folders/train\", transform = transformer) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yi5yHsIRKTU-",
        "outputId": "a548a1d3-2a99-44d0-81ee-9f60e6756c7f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bf2d_1toKqsD"
      },
      "source": [
        "image_size = 128\n",
        "batch_size = 64"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXe0_ovEKm0q"
      },
      "source": [
        "from torchvision import transforms\n",
        "transformer = transforms.Compose([\n",
        "  transforms.Resize((image_size, image_size)),       \n",
        "  transforms.ToTensor(),                     \n",
        "  transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5] )])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnihKRVmKTVC"
      },
      "source": [
        "from torchvision import datasets\n",
        "train_dataset = datasets.ImageFolder(root = \"/content/gdrive/MyDrive/Image folders/train\", transform = transformer)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhHOwRz3KTVD"
      },
      "source": [
        "import torch.utils.data as Data\n",
        "train_dl = Data.DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bVl0ZE2JpBZ"
      },
      "source": [
        "### Step-by-step run to understand train_discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jp3s9--0ikKT"
      },
      "source": [
        "import torch.nn.functional as F"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84ibNmVtJuHo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58ee1506-6dcd-4d62-ac4a-4b2b58ba4ee7"
      },
      "source": [
        "for real_images, _ in train_dl:\n",
        "  break\n",
        "print(real_images.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 3, 128, 128])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xU4SDuGyLk8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a7c82a4-7da9-4cae-fe17-b082551a205a"
      },
      "source": [
        "real_preds = discriminator(real_images.to(device))\n",
        "print(real_preds.shape, real_preds[0])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 1]) tensor([0.3178], device='cuda:0', grad_fn=<SelectBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LxF7CvpL3Cw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4d17780-4e26-43bb-d892-830f3e6a15a2"
      },
      "source": [
        "real_targets = torch.ones(real_images.size(0), 1, device=device)\n",
        "print(real_targets.shape) # every value is 1 for real image"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jtE2MmuMEyx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ef0c26a-6695-4661-d5f0-7a1c5cee853e"
      },
      "source": [
        "real_loss = F.binary_cross_entropy(real_preds, real_targets)\n",
        "print(real_loss)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.8455, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezB09pEmMPP3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05d14d79-462a-4524-a17e-1e6066b21c92"
      },
      "source": [
        "real_score = torch.mean(real_preds).item()\n",
        "print(real_score)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.4373319745063782\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khrZ4omoMSri",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "560c0c75-7bf4-4126-b5f9-384bb2464b56"
      },
      "source": [
        "# Generate latent vector for fake images generation\n",
        "latent = torch.randn(batch_size, latent_size, 1, 1, device=device)\n",
        "print(latent.shape)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 64, 1, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQpDiU61MX-I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46d13671-eeba-44fb-c0e3-8f238df33ebe"
      },
      "source": [
        "fake_images = generator(latent.to(device))\n",
        "print(fake_images.shape)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 3, 128, 128])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BQ3qiVQNoWy",
        "outputId": "ed8a0e62-4a36-47ac-f60f-2de11d2670cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Pass fake images through discriminator\n",
        "fake_targets = torch.zeros(fake_images.size(0), 1, device=device)\n",
        "fake_preds = discriminator(fake_images)\n",
        "fake_loss = F.binary_cross_entropy(fake_preds, fake_targets)\n",
        "fake_score = torch.mean(fake_preds).item()\n",
        "print(fake_score)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.43478113412857056\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D54wmcOl87Fx"
      },
      "source": [
        "def train_discriminator(real_images, opt_d):\n",
        "  # Clear discriminator gradients\n",
        "  opt_d.zero_grad()\n",
        "\n",
        "  # Pass real images through discriminator\n",
        "  real_preds = discriminator(real_images)\n",
        "  real_targets = torch.ones(real_images.size(0), 1, device=device)\n",
        "  real_loss = F.binary_cross_entropy(real_preds, real_targets)\n",
        "  real_score = torch.mean(real_preds).item()\n",
        "  \n",
        "  # Generate fake images\n",
        "  latent = torch.randn(batch_size, latent_size, 1, 1, device=device)\n",
        "  fake_images = generator(latent.to(device))\n",
        "\n",
        "  # Pass fake images through discriminator\n",
        "  fake_targets = torch.zeros(fake_images.size(0), 1, device=device)\n",
        "  fake_preds = discriminator(fake_images)\n",
        "  fake_loss = F.binary_cross_entropy(fake_preds, fake_targets)\n",
        "  fake_score = torch.mean(fake_preds).item()\n",
        "\n",
        "  # Update discriminator weights\n",
        "  loss = real_loss + fake_loss\n",
        "  loss.backward()\n",
        "  opt_d.step()\n",
        "  return loss.item(), real_score, fake_score"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrrgPeEi07sb"
      },
      "source": [
        "def train_generator(opt_g):\n",
        "  # Clear generator gradients\n",
        "  opt_g.zero_grad()\n",
        "  \n",
        "  # Generate fake images\n",
        "  latent = torch.randn(batch_size, latent_size, 1, 1, device=device)\n",
        "  fake_images = generator(latent)\n",
        "  \n",
        "  # Try to fool the discriminator\n",
        "  preds = discriminator(fake_images)\n",
        "  targets = torch.ones(batch_size, 1, device=device)\n",
        "  loss = F.binary_cross_entropy(preds, targets)\n",
        "  \n",
        "  # Update generator weights\n",
        "  loss.backward()\n",
        "  opt_g.step()\n",
        "  \n",
        "  return loss.item()"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uc_GmVXLK6wI"
      },
      "source": [
        "# Image saving untility functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TBoQRJ_qqtD"
      },
      "source": [
        "from torchvision.utils import save_image"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNbUlAzirH5k"
      },
      "source": [
        "stats = (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Z_ywnhFK4OE"
      },
      "source": [
        "def denorm(img_tensors):\n",
        "  return img_tensors * stats[1][0] + stats[0][0]"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPvrJdxxK4OG"
      },
      "source": [
        "import os\n",
        "sample_dir = 'generated'\n",
        "os.makedirs(sample_dir, exist_ok=True)\n",
        "\n",
        "def save_samples(index, latent_tensors, show=True):\n",
        "  fake_images = generator(latent_tensors)\n",
        "  fake_fname = 'generated-images-{0:0=4d}.png'.format(index)\n",
        "  save_image(denorm(fake_images), os.path.join(sample_dir, fake_fname), nrow=8)\n",
        "  print('Saving', fake_fname)\n",
        "  if show:\n",
        "    fig, ax = plt.subplots(figsize=(8, 8))\n",
        "    ax.set_xticks([]); ax.set_yticks([])\n",
        "    ax.imshow(make_grid(fake_images.cpu().detach(), nrow=8).permute(1, 2, 0))"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14xm6dnAmGvd"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoBnqeNJ2bhs"
      },
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4r_GMbwrNRT"
      },
      "source": [
        "# Losses & scores\n",
        "losses_g = []\n",
        "losses_d = []\n",
        "real_scores = []\n",
        "fake_scores = []"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crH70nd1hHd7"
      },
      "source": [
        "lr = 0.0002"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Bnb2FP62hcx"
      },
      "source": [
        "# Create optimizers\n",
        "opt_d = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "opt_g = torch.optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcjrZR2s3_Vj"
      },
      "source": [
        "epochs =60\n",
        "start_idx=1"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpNSL9pZsxSu"
      },
      "source": [
        "for epoch in range(epochs):\n",
        "  if(epoch % 10 ==0):\n",
        "    print(epoch, end=\",\")\n",
        "  for real_images, _ in train_dl:\n",
        "    # Train discriminator\n",
        "    loss_d, real_score, fake_score = train_discriminator(real_images.to(device), opt_d)\n",
        "    # Train generator\n",
        "    loss_g = train_generator(opt_g)\n",
        "      \n",
        "  # Record losses & scores\n",
        "  losses_g.append(loss_g)\n",
        "  losses_d.append(loss_d)\n",
        "  real_scores.append(real_score)\n",
        "  fake_scores.append(fake_score)\n",
        "  \n",
        "  if(epoch % 20 ==0):\n",
        "    # Log losses & scores (last batch)\n",
        "    print(\"Epoch [{}/{}], loss_g: {:.4f}, loss_d: {:.4f}, real_score: {:.4f}, fake_score: {:.4f}\".format(\n",
        "        epoch+1, epochs, loss_g, loss_d, real_score, fake_score))\n",
        "    # Save generated images\n",
        "    latent = torch.randn(batch_size, latent_size, 1, 1, device=device)\n",
        "    save_samples(epoch+start_idx, latent, show=False)\n",
        "    #save_samples(epoch+start_idx, fixed_latent, show=False)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8i1YNFJ8raP4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}